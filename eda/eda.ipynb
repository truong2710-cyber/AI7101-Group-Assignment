{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ae3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from matplotlib.dates import AutoDateLocator, ConciseDateFormatter\n",
    "from scipy.stats import gaussian_kde, norm\n",
    "from collections import Counter\n",
    "plt.rcParams.update({'figure.dpi': 400})\n",
    "os.makedirs('../imgs',exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0afe3e",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dbd121",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../dataset/Train.csv')\n",
    "test = pd.read_csv('../dataset/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57dc053",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db0bd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc273a7",
   "metadata": {},
   "source": [
    "# Null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_report(df):\n",
    "    groups = defaultdict(list)\n",
    "    for c in df.columns:\n",
    "        if \"_\" in c:\n",
    "            groups[c.split(\"_\", 1)[0]].append(c)\n",
    "    prefixes_to_check = [\n",
    "        \"sulphurdioxide\",\"carbonmonoxide\",\"nitrogendioxide\",\"formaldehyde\",\n",
    "        \"uvaerosolindex\",\"ozone\",\"uvaerosollayerheight\",\"cloud\"\n",
    "    ]\n",
    "    groups = {k:v for k,v in groups.items() if k in prefixes_to_check and len(v) >= 2}\n",
    "\n",
    "    # Check consistency of missing values in each group\n",
    "    report_rows = []\n",
    "    bad_row_idx = set()\n",
    "\n",
    "    for pref, cols in groups.items():\n",
    "        na_cnt = df[cols].isna().sum(axis=1)       \n",
    "        ncols = len(cols)\n",
    "        partial = (na_cnt > 0) & (na_cnt < ncols)      # partially missing\n",
    "        any_na = na_cnt > 0\n",
    "        all_na = na_cnt == ncols\n",
    "\n",
    "        bad_row_idx.update(df.index[partial])\n",
    "\n",
    "        report_rows.append({\n",
    "            \"prefix\": pref,\n",
    "            \"n_cols\": ncols,\n",
    "            \"rows_total\": len(df),\n",
    "            \"rows_any_NA\": int(any_na.sum()),\n",
    "            \"rows_all_NA\": int(all_na.sum()),\n",
    "            \"rows_partial_NA\": int(partial.sum()),\n",
    "            \"OK_all_or_nothing\": bool(partial.sum() == 0)\n",
    "        })\n",
    "\n",
    "    report = pd.DataFrame(report_rows).sort_values(\"prefix\")\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eceac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_train, report_test = get_null_report(train), get_null_report(test) #print will get all rows with same prefix full or nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a796eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_train = report_train.sort_values('rows_all_NA', ascending=False)\n",
    "prefixes = report_train['prefix'].tolist()\n",
    "x = np.arange(len(prefixes))\n",
    "width = 0.28\n",
    "\n",
    "\n",
    "y_all = report_train['rows_all_NA'].to_numpy()\n",
    "\n",
    "tot = report_train['rows_total'].to_numpy()\n",
    "\n",
    "# hbar plot with percentage labels\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.barh(prefixes, y_all)\n",
    "for i, v in enumerate(y_all):\n",
    "    pct = 100.0 * v / tot[i]\n",
    "    plt.text(v, i, f' {v} ({pct:.1f}%)', va='center')\n",
    "plt.xlabel('Number of rows')\n",
    "plt.title('Percentage of completely missing rows by prefix - Train')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../imgs/missing_rows_train.png')\n",
    "plt.savefig('../imgs/missing_rows_train.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_test = report_test.sort_values('rows_all_NA', ascending=False)\n",
    "prefixes = report_test['prefix'].tolist()\n",
    "x = np.arange(len(prefixes))\n",
    "width = 0.28\n",
    "\n",
    "\n",
    "y_all = report_test['rows_all_NA'].to_numpy()\n",
    "\n",
    "tot = report_test['rows_total'].to_numpy()\n",
    "\n",
    "# hbar plot with percentage labels\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.barh(prefixes, y_all)\n",
    "for i, v in enumerate(y_all):\n",
    "    pct = 100.0 * v / tot[i]\n",
    "    plt.text(v, i, f' {v} ({pct:.1f}%)', va='center')\n",
    "plt.xlabel('Number of rows')\n",
    "plt.title('Percentage of completely missing rows by prefix - Test')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../imgs/missing_rows_test.png')\n",
    "plt.savefig('../imgs/missing_rows_test.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935f3d",
   "metadata": {},
   "source": [
    "# Analysis of Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c661579",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train.groupby('city').agg(\n",
    "    num_sites=('site_id', 'nunique'),\n",
    "    num_samples=('site_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "test_stats = test.groupby('city').agg(\n",
    "    num_sites=('site_id', 'nunique'),\n",
    "    num_samples=('site_id', 'count')\n",
    ").reset_index()\n",
    "\n",
    "max_site = max(train_stats['num_sites'].max(), test_stats['num_sites'].max()) + 2\n",
    "max_sample = max(train_stats['num_samples'].max(), test_stats['num_samples'].max()) + 400\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6), sharey=False)\n",
    "width = 0.4\n",
    "\n",
    "# TRAIN\n",
    "x1 = np.arange(len(train_stats))\n",
    "bars1_sites = ax1.bar(x1 - width/2, train_stats['num_sites'], width, color='dodgerblue', label='Sites')\n",
    "ax1.set_ylabel('Number of Sites', color='dodgerblue')\n",
    "ax1.tick_params(axis='y', labelcolor='dodgerblue')\n",
    "ax1.set_ylim(0, max_site)\n",
    "\n",
    "ax1b = ax1.twinx()\n",
    "bars1_samples = ax1b.bar(x1 + width/2, train_stats['num_samples'], width, color='tomato', label='Samples')\n",
    "ax1b.set_ylabel('Number of Samples', color='tomato')\n",
    "ax1b.tick_params(axis='y', labelcolor='tomato')\n",
    "ax1b.set_ylim(0, max_sample)\n",
    "\n",
    "ax1.set_xticks(x1)\n",
    "ax1.set_xticklabels(train_stats['city'], rotation=45)\n",
    "ax1.set_title('Train Data')\n",
    "\n",
    "for bar in bars1_sites:\n",
    "    height = bar.get_height()\n",
    "    ax1.annotate(f'{height}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                 xytext=(0, 3), textcoords=\"offset points\", ha='center', fontsize=9, color='dodgerblue')\n",
    "\n",
    "for bar in bars1_samples:\n",
    "    height = bar.get_height()\n",
    "    ax1b.annotate(f'{height}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                  xytext=(0, 3), textcoords=\"offset points\", ha='center', fontsize=9, color='tomato')\n",
    "\n",
    "# TEST\n",
    "x2 = np.arange(len(test_stats))\n",
    "bars2_sites = ax2.bar(x2 - width/2, test_stats['num_sites'], width, color='royalblue', label='Sites')\n",
    "ax2.set_ylabel('Number of Sites', color='royalblue')\n",
    "ax2.tick_params(axis='y', labelcolor='royalblue')\n",
    "ax2.set_ylim(0, max_site)\n",
    "\n",
    "ax2b = ax2.twinx()\n",
    "bars2_samples = ax2b.bar(x2 + width/2, test_stats['num_samples'], width, color='firebrick', label='Samples')\n",
    "ax2b.set_ylabel('Number of Samples', color='firebrick')\n",
    "ax2b.tick_params(axis='y', labelcolor='firebrick')\n",
    "ax2b.set_ylim(0, max_sample)\n",
    "\n",
    "ax2.set_xticks(x2)\n",
    "ax2.set_xticklabels(test_stats['city'], rotation=45)\n",
    "ax2.set_title('Test Data')\n",
    "\n",
    "\n",
    "for bar in bars2_sites:\n",
    "    height = bar.get_height()\n",
    "    ax2.annotate(f'{height}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                 xytext=(0, 3), textcoords=\"offset points\", ha='center', fontsize=9, color='royalblue')\n",
    "\n",
    "\n",
    "for bar in bars2_samples:\n",
    "    height = bar.get_height()\n",
    "    ax2b.annotate(f'{height}', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                  xytext=(0, 3), textcoords=\"offset points\", ha='center', fontsize=9, color='firebrick')\n",
    "\n",
    "fig.suptitle('Sites and Samples per City (Train vs Test)', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.savefig('../imgs/sites_samples_per_city.png')\n",
    "plt.savefig('../imgs/sites_samples_per_city.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d772e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) Chuẩn hoá & đếm ---\n",
    "def prep_counts(df, lat_col='site_latitude', lon_col='site_longitude', decimals=3):\n",
    "    tmp = df.copy()\n",
    "    tmp['lat'] = tmp[lat_col].round(decimals)\n",
    "    tmp['lon'] = tmp[lon_col].round(decimals)\n",
    "    out = tmp.groupby(['lat', 'lon'], as_index=False).size()\n",
    "    out.rename(columns={'size': 'count'}, inplace=True)\n",
    "    return out\n",
    "\n",
    "train_counts = prep_counts(train)\n",
    "test_counts  = prep_counts(test)\n",
    "\n",
    "# --- 2) Scale kích thước dùng chung ---\n",
    "max_count = max(train_counts['count'].max(), test_counts['count'].max())\n",
    "size_scale = 800 / max_count  # chỉnh 800 cho hợp mắt\n",
    "\n",
    "# --- 3) Vẽ: khác marker, có viền, zorder ---\n",
    "plt.figure(figsize=(10, 20))\n",
    "eps = 0.03  # 4) jitter nhẹ\n",
    "plt.scatter(train_counts['lon']-eps, train_counts['lat']-eps,\n",
    "            s=train_counts['count'] * size_scale, marker='o',\n",
    "            c='tab:blue', alpha=0.6, label='Train',\n",
    "            edgecolors='white', linewidth=0.7, zorder=2)\n",
    "\n",
    "plt.scatter(test_counts['lon']+eps, test_counts['lat']+eps,\n",
    "            s=test_counts['count'] * size_scale, marker='s',\n",
    "            c='tab:green', alpha=0.6, label='Test',\n",
    "            edgecolors='white', linewidth=0.7, zorder=3)\n",
    "\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Bubble Plot of Measurement Sites (Train vs Test)')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':', alpha=0.6)\n",
    "plt.gca().set_aspect('equal', adjustable='box')  # 5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../imgs/sites_per_location.png')\n",
    "plt.savefig('../imgs/sites_per_location.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c2a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = [\n",
    "        \"sulphurdioxide\",\"carbonmonoxide\",\"nitrogendioxide\",\"formaldehyde\",\n",
    "        \"uvaerosolindex\",\"ozone\",\"uvaerosollayerheight\",\"cloud\"\n",
    "    ]\n",
    "def plot_null_city_date(train,test,prefix):\n",
    "    assert prefix in prefixes, \"Invalid prefix\"\n",
    "    \n",
    "    tr = train.copy()\n",
    "    te = test.copy()\n",
    "    tr['date'] = pd.to_datetime(tr['date'], errors='coerce')\n",
    "    te['date'] = pd.to_datetime(te['date'], errors='coerce')\n",
    "    tr = tr.dropna(subset=['date'])\n",
    "    te = te.dropna(subset=['date'])\n",
    "    tr_cities = pd.unique(tr['city'])\n",
    "    te_cities = pd.unique(te['city'])\n",
    "    \n",
    "    # Map y (train/test) + jitter\n",
    "    gap = 1\n",
    "    te_map = {c: i for i, c in enumerate(te_cities, start=1)}                       # 1..4\n",
    "    tr_map = {c: len(te_cities) + gap + i for i, c in enumerate(tr_cities, start=1)}# 6..9\n",
    "    rng = np.random.default_rng(42)\n",
    "    tr['_y'] = tr['city'].map(tr_map) + rng.uniform(-0.06, 0.06, len(tr))\n",
    "    te['_y'] = te['city'].map(te_map) + rng.uniform(-0.06, 0.06, len(te))\n",
    "    \n",
    "    for col in train.columns:\n",
    "        if col.startswith(prefix+\"_\"):\n",
    "            check_null = col\n",
    "            break\n",
    "    tr_na = tr[tr[check_null].isna()]\n",
    "    te_na = te[te[check_null].isna()]\n",
    "    tr_full = tr[tr[check_null].notna()]\n",
    "    te_full = te[te[check_null].notna()]\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.scatter(tr_na['date'], tr_na['_y'], s=18, alpha=0.8, label='Train-null', c='lightsteelblue')\n",
    "    ax.scatter(te_na['date'], te_na['_y'], s=18, alpha=0.8, label='Test-null',  c='peachpuff')\n",
    "    ax.scatter(tr_full['date'], tr_full['_y'], s=6, alpha=0.8, label='Train-full', c='tab:blue')\n",
    "    ax.scatter(te_full['date'], te_full['_y'], s=6, alpha=0.8, label='Test-full', c='tab:orange')\n",
    "\n",
    "    yticks  = list(te_map.values()) + list(tr_map.values())\n",
    "    ylabels = list(te_cities)       + list(tr_cities)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(ylabels)\n",
    "    ax.set_ylim(0.5, (len(te_cities) + len(tr_cities)) + 1.5 )\n",
    "    ax.axhline(len(te_cities)+0.5, linestyle='--', alpha=0.3)\n",
    "    \n",
    "    loc = AutoDateLocator()\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.xaxis.set_major_formatter(ConciseDateFormatter(loc))\n",
    "    \n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('City')\n",
    "    ax.set_title('City–Date scatter: Missing values for attribute \"{}\"'.format(prefix))\n",
    "    ax.grid(axis='x', linestyle=':', alpha=0.6)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = [\n",
    "        \"sulphurdioxide\",\"carbonmonoxide\",\"nitrogendioxide\",\"formaldehyde\",\n",
    "        \"uvaerosolindex\",\"ozone\",\"uvaerosollayerheight\",\"cloud\"\n",
    "    ]\n",
    "def plot_null_city_date(train, test, prefix, ax=None, show_legend=True):\n",
    "    assert prefix in prefixes, \"Invalid prefix\"\n",
    "    \n",
    "    tr = train.copy()\n",
    "    te = test.copy()\n",
    "    tr['date'] = pd.to_datetime(tr['date'], errors='coerce')\n",
    "    te['date'] = pd.to_datetime(te['date'], errors='coerce')\n",
    "    tr = tr.dropna(subset=['date'])\n",
    "    te = te.dropna(subset=['date'])\n",
    "    tr_cities = pd.unique(tr['city'])\n",
    "    te_cities = pd.unique(te['city'])\n",
    "    \n",
    "    # Map y (train/test) + jitter\n",
    "    gap = 1\n",
    "    te_map = {c: i for i, c in enumerate(te_cities, start=1)}                       # 1..n\n",
    "    tr_map = {c: len(te_cities) + gap + i for i, c in enumerate(tr_cities, start=1)}# ...\n",
    "    rng = np.random.default_rng(42)\n",
    "    tr['_y'] = tr['city'].map(tr_map) + rng.uniform(-0.06, 0.06, len(tr))\n",
    "    te['_y'] = te['city'].map(te_map) + rng.uniform(-0.06, 0.06, len(te))\n",
    "\n",
    "    for col in train.columns:\n",
    "        if col.startswith(prefix + \"_\"):\n",
    "            check_null = col\n",
    "            break\n",
    "\n",
    "    tr_na = tr[tr[check_null].isna()]\n",
    "    te_na = te[te[check_null].isna()]\n",
    "    tr_full = tr[tr[check_null].notna()]\n",
    "    te_full = te[te[check_null].notna()]\n",
    "\n",
    "    # dùng ax được truyền vào; nếu không có thì tự tạo\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    ax.scatter(tr_na['date'], tr_na['_y'], s=18, alpha=0.8, label='Train-null', c='lightsteelblue')\n",
    "    ax.scatter(te_na['date'], te_na['_y'], s=18, alpha=0.8, label='Test-null',  c='peachpuff')\n",
    "    ax.scatter(tr_full['date'], tr_full['_y'], s=6,  alpha=0.8, label='Train-full', c='tab:blue')\n",
    "    ax.scatter(te_full['date'], te_full['_y'], s=6,  alpha=0.8, label='Test-full',  c='tab:orange')\n",
    "\n",
    "    yticks  = list(te_map.values()) + list(tr_map.values())\n",
    "    ylabels = list(te_cities)       + list(tr_cities)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_ylim(0.5, (len(te_cities) + len(tr_cities)) + 1.5 )\n",
    "    \n",
    "    # only show y on left hand side\n",
    "    if ax.get_subplotspec().is_first_col():\n",
    "        ax.set_yticklabels(ylabels)\n",
    "    else:\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "    ax.axhline(len(te_cities)+0.5, linestyle='--', alpha=0.3)\n",
    "\n",
    "    loc = AutoDateLocator()\n",
    "    ax.xaxis.set_major_locator(loc)\n",
    "    ax.xaxis.set_major_formatter(ConciseDateFormatter(loc))\n",
    "\n",
    "    ax.set_xlabel('Date')\n",
    "    if ax.get_subplotspec().is_first_col():\n",
    "        ax.set_ylabel('City')\n",
    "    ax.set_title(f'Nulls: \"{prefix}\"')\n",
    "\n",
    "    ax.grid(axis='x', linestyle=':', alpha=0.6)\n",
    "    if show_legend:\n",
    "        ax.legend()\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e61989",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 4, 2\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(18, 20), sharex=True, sharey=True)\n",
    "\n",
    "handles = labels = None\n",
    "for i, prefix in enumerate(prefixes):\n",
    "    ax = axs.flat[i]\n",
    "    fig, ax = plot_null_city_date(train, test, prefix, ax=ax, show_legend=True)\n",
    "    if i == 0:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "fig.suptitle('City–Date scatter: Missing values by attribute', y=0.995)\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "plt.savefig('../imgs/missing_values_by_attribute.png')\n",
    "plt.savefig('../imgs/missing_values_by_attribute.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data\n",
    "\n",
    "# transform date colums to datetime\n",
    "tr = train.copy()\n",
    "te = test.copy()\n",
    "tr['date'] = pd.to_datetime(tr['date'], errors='coerce')\n",
    "te['date'] = pd.to_datetime(te['date'], errors='coerce')\n",
    "tr = tr.dropna(subset=['date'])\n",
    "te = te.dropna(subset=['date'])\n",
    "\n",
    "# get cities list\n",
    "tr_cities = pd.unique(tr['city'])\n",
    "te_cities = pd.unique(te['city'])\n",
    "\n",
    "# Map y (train/test) + jitter\n",
    "te_map = {c: i for i, c in enumerate(te_cities, start=1)}\n",
    "tr_map = {c: len(te_cities) + i for i, c in enumerate(tr_cities, start=1)}\n",
    "rng = np.random.default_rng(42)\n",
    "tr['_y'] = tr['city'].map(tr_map) + rng.uniform(-0.06, 0.06, len(tr))\n",
    "te['_y'] = te['city'].map(te_map) + rng.uniform(-0.06, 0.06, len(te))\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.scatter(tr['date'], tr['_y'], s=18, alpha=0.8, label='Train', c='tab:blue')\n",
    "ax.scatter(te['date'], te['_y'], s=18, alpha=0.8, label='Test',  c='tab:orange')\n",
    "\n",
    "yticks  = list(te_map.values()) + list(tr_map.values())\n",
    "ylabels = list(te_cities)       + list(tr_cities)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(ylabels)\n",
    "ax.set_ylim(0.5, (len(te_cities) + len(tr_cities)) + 0.5)\n",
    "ax.axhline(len(te_cities)+0.5, linestyle='--', alpha=0.3)\n",
    "\n",
    "loc = AutoDateLocator()\n",
    "ax.xaxis.set_major_locator(loc)\n",
    "ax.xaxis.set_major_formatter(ConciseDateFormatter(loc))\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('City')\n",
    "ax.set_title('Train (top) vs Test (bottom): City–Date scatter')\n",
    "ax.grid(axis='x', linestyle=':', alpha=0.6)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../imgs/train_test_city_time.png')\n",
    "plt.savefig('../imgs/train_test_city_time.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b2b2fe",
   "metadata": {},
   "source": [
    "# Target variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities =  ['Kampala','Bujumbura','Lagos','Nairobi']\n",
    "def hist_by_city(df,city):\n",
    "    assert city in ['Kampala','Bujumbura','Lagos','Nairobi']\n",
    "    y = df[df['city'] == city]['pm2_5']\n",
    "    ys = np.linspace(y.min(), y.max(), 600)\n",
    "    kde = gaussian_kde(y)\n",
    "    return y, kde(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b79f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "for i in range(4):\n",
    "    city = cities[i]\n",
    "    y, kde_y = hist_by_city(train, city)\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.hist(y, bins=50, density=False, color='tab:green', rwidth=1.0, edgecolor='gray', linewidth=0.4, alpha=0.45, histtype='bar')\n",
    "    plt.title(city)\n",
    "    plt.xlabel('PM2.5 Value'); plt.ylabel('Count')\n",
    "    plt.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../imgs/pm25_distribution_by_city.png')\n",
    "plt.savefig('../imgs/pm25_distribution_by_city.pdf')\n",
    "plt.suptitle('Distribution of PM2.5 Values by City', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e3cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['pm2_5'].to_numpy(float)\n",
    "y = y[np.isfinite(y)]\n",
    "y_pos = y[y > 0]\n",
    "\n",
    "xs_lin = np.linspace(y.min(), y.max(), 600)\n",
    "kde_lin = gaussian_kde(y)          # KDE /x (linear)\n",
    "\n",
    "# KDE /log(x)\n",
    "xs_log = np.logspace(np.log10(y_pos.min()), np.log10(y_pos.max()), 600)\n",
    "z = np.log(y_pos)\n",
    "kde_log = gaussian_kde(z)\n",
    "pdf_logspace = kde_log(np.log(xs_log)) / xs_log\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ==== Left: linear ====\n",
    "axes[0].hist(\n",
    "    y, bins=50, density=True, color='tab:green',\n",
    "    rwidth=1.0, edgecolor='gray', linewidth=0.4, alpha=0.45, histtype='bar'\n",
    ")\n",
    "axes[0].plot(xs_lin, kde_lin(xs_lin), linewidth=1, alpha=0.7, label='KDE')\n",
    "axes[0].set_title('PM2.5 (linear x)')\n",
    "axes[0].set_xlabel('PM2.5 Value'); axes[0].set_ylabel('Density')\n",
    "axes[0].grid(axis='y', linestyle=':', alpha=0.6)\n",
    "axes[0].legend()\n",
    "\n",
    "# ==== Right: log ====\n",
    "bins_log = np.logspace(np.log10(y_pos.min()), np.log10(y_pos.max()), 50)\n",
    "axes[1].hist(\n",
    "    y_pos, bins=bins_log, density=True, color='tab:green',\n",
    "    rwidth=1.0, edgecolor='gray', linewidth=0.4, alpha=0.45, histtype='bar'\n",
    ")\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].plot(xs_log, kde_lin(xs_log), linewidth=1, alpha=0.7, label='KDE on x')\n",
    "axes[1].plot(xs_log, pdf_logspace, linestyle='--', linewidth=1, alpha=0.9, label='KDE on log(x)')\n",
    "axes[1].set_title('PM2.5 (log x)')\n",
    "axes[1].set_xlabel('PM2.5 Value')\n",
    "axes[1].grid(axis='y', which='both', linestyle=':', alpha=0.6)\n",
    "axes[1].set_xlim(right= y_pos.max()*0.9)\n",
    "axes[1].legend()\n",
    "\n",
    "fig.suptitle('Distribution of PM2.5 Values in Training Data', y=0.98)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('../imgs/pm25_distribution.png', dpi=150)\n",
    "fig.savefig('../imgs/pm25_distribution.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42952f6f",
   "metadata": {},
   "source": [
    "PM2.5 vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96651490",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()\n",
    "df = df[np.isfinite(df['pm2_5'])]\n",
    "df['month'] = pd.Categorical(df['month'].astype(int),\n",
    "                             categories=range(1, 12+1), ordered=True)\n",
    "\n",
    "sns.set_theme(style='whitegrid', context='notebook')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df, x='month', y='pm2_5',\n",
    "    hue='month',     \n",
    "    dodge=False,\n",
    "    palette='Set2',\n",
    "    width=0.6, linewidth=1.1,\n",
    "    showfliers=True,       \n",
    "    whis=(5, 95),\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('PM2.5')\n",
    "ax.set_title('PM2.5 by Month')\n",
    "\n",
    "upper = np.nanpercentile(df['pm2_5'], 99)\n",
    "ax.set_ylim(0, upper * 1.05)\n",
    "\n",
    "ax.grid(axis='y', linestyle=':', alpha=0.6)\n",
    "fig.tight_layout()\n",
    "plt.legend('')\n",
    "\n",
    "fig.savefig('../imgs/pm25_by_month_box.png')\n",
    "fig.savefig('../imgs/pm25_by_month_box.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a7d45",
   "metadata": {},
   "source": [
    "# Feature correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_selected_features = ['id', 'site_id', 'site_latitude', 'site_longitude', 'city', 'country', 'date', 'hour', 'month',\n",
    "                         ]\n",
    "feats = train.copy()\n",
    "feats = feats.drop(columns=not_selected_features)\n",
    "corr = feats.corr()\n",
    "cols = corr.columns.tolist()\n",
    "id_map = {col: i+1 for i, col in enumerate(cols)}         # {'very_long_name': 1, ...}\n",
    "\n",
    "# Colname to ID because there are too many long names\n",
    "corr_id = corr.copy()\n",
    "corr_id.index   = [id_map[c] for c in cols]\n",
    "corr_id.columns = [id_map[c] for c in cols]\n",
    "\n",
    "# upper half mask\n",
    "mask = np.triu(np.ones_like(corr_id, dtype=bool), k=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    corr_id, mask=mask, cmap='coolwarm', center=0, square=True,\n",
    "    cbar_kws={'shrink': 0.8}, linewidths=0.2, linecolor='white', ax=ax\n",
    ")\n",
    "ax.set_xlabel('Feature ID'); ax.set_ylabel('Feature ID')\n",
    "ax.set_title('Feature Correlation (by ID)')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../imgs/feature_correlation_original.png')\n",
    "plt.savefig('../imgs/feature_correlation_original.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0499236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[col for col in train.columns if col.startswith('cloud_')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d036556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_corr_pairs(corr, id_map, top_n=30, min_abs=0.8):\n",
    "    mask = np.triu(np.ones(corr.shape, dtype=bool), k=1)\n",
    "    df = corr.where(mask).stack().reset_index()\n",
    "    df.columns = ['feature1', 'feature2', 'corr']\n",
    "    df['abs_corr'] = df['corr'].abs()\n",
    "    df['id1'] = df['feature1'].map(id_map)\n",
    "    df['id2'] = df['feature2'].map(id_map)\n",
    "    out = df[df['abs_corr'] >= min_abs].sort_values('abs_corr', ascending=False)\n",
    "    if top_n is not None:\n",
    "        out = out.head(top_n)\n",
    "    return out[['id1','id2','corr','abs_corr','feature1','feature2']]\n",
    "\n",
    "top_pairs = top_corr_pairs(corr, id_map, top_n=30, min_abs=0.7)\n",
    "top_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8bf3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_with_majority(df, new_col='sensor_zenith_angle', decimals=3):\n",
    "    src_cols = [c for c in df.columns if new_col in c and c != new_col]\n",
    "    if not src_cols:\n",
    "        return df\n",
    "\n",
    "    # force numeric for row_majority function\n",
    "    src_raw = df[src_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    src_rnd = src_raw.round(decimals)\n",
    "\n",
    "    def row_majority(i):\n",
    "        rnd = src_rnd.iloc[i].dropna()\n",
    "        raw = src_raw.iloc[i].dropna()\n",
    "        if rnd.empty:\n",
    "            return np.nan\n",
    "\n",
    "        cnt = Counter(rnd.values.tolist())\n",
    "        maxc = max(cnt.values())\n",
    "        # Take majority values\n",
    "        tops = sorted([v for v, k in cnt.items() if k == maxc])\n",
    "        chosen_r = tops[0]\n",
    "\n",
    "        # median of original values corresponding to the chosen rounded value\n",
    "        mask = (src_rnd.iloc[i] == chosen_r) & src_raw.iloc[i].notna()\n",
    "        cand = src_raw.iloc[i][mask].values\n",
    "        if cand.size:\n",
    "            return float(np.median(cand))\n",
    "        # fallback: first value\n",
    "        return float(raw.iloc[0]) if not raw.empty else np.nan\n",
    "\n",
    "    df[new_col] = [row_majority(i) for i in range(len(df))]\n",
    "\n",
    "    # drop source columns\n",
    "    df = df.drop(columns=src_cols)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93663af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.copy()\n",
    "df = df.drop(columns=not_selected_features)\n",
    "df = unify_with_majority(df, new_col='sensor_zenith_angle', decimals=3)\n",
    "df = unify_with_majority(df, new_col='sensor_azimuth_angle', decimals=3)\n",
    "df = unify_with_majority(df, new_col='solar_zenith_angle', decimals=3)\n",
    "df = unify_with_majority(df, new_col='solar_azimuth_angle', decimals=3)\n",
    "df = unify_with_majority(df, new_col='altitude', decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7608b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "uva = ['uvaerosollayerheight_aerosol_height',\n",
    " 'uvaerosollayerheight_aerosol_pressure',\n",
    " 'uvaerosollayerheight_aerosol_optical_depth']\n",
    "df = df.drop(columns=uva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511c6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "cols = corr.columns.tolist()\n",
    "id_map = {col: i+1 for i, col in enumerate(cols)}         # {'very_long_name': 1, ...}\n",
    "\n",
    "# Colname to ID because there are too many long names\n",
    "corr_id = corr.copy()\n",
    "corr_id.index   = [id_map[c] for c in cols]\n",
    "corr_id.columns = [id_map[c] for c in cols]\n",
    "\n",
    "# upper half mask\n",
    "mask = np.triu(np.ones_like(corr_id, dtype=bool), k=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    corr_id, mask=mask, cmap='coolwarm', center=0, square=True,\n",
    "    cbar_kws={'shrink': 0.8}, linewidths=0.2, linecolor='white', ax=ax\n",
    ")\n",
    "ax.set_xlabel('Feature ID'); ax.set_ylabel('Feature ID')\n",
    "ax.set_title('Feature Correlation (by ID)')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "plt.tight_layout()\n",
    "# plt.savefig('../imgs/feature_correlation_new.png')\n",
    "# plt.savefig('../imgs/feature_correlation_new.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44286171",
   "metadata": {},
   "source": [
    "Finally: Target variable correlation with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c814a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_with_target(corr, target='pm2_5', id_map=None, top_n=20):\n",
    "    s = corr[target].drop(target).dropna()\n",
    "    out = (pd.DataFrame({'feature': s.index, 'corr': s.values})\n",
    "             .assign(abs_corr=lambda d: d['corr'].abs())\n",
    "             .sort_values('abs_corr', ascending=False)\n",
    "             .head(top_n))\n",
    "    if id_map:\n",
    "        out.insert(0, 'id', out['feature'].map(id_map))\n",
    "    return out[['id','corr','abs_corr','feature']] if id_map else out\n",
    "\n",
    "top_target = top_with_target(corr, target='pm2_5', id_map=id_map, top_n=20)\n",
    "top_target"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
