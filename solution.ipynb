{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    target_col = 'pm2_5'\n",
    "    n_splits = 4\n",
    "    random_state = 42\n",
    "    id_col = 'id'\n",
    "    missing_threshold = 0.7\n",
    "    top_features = 70\n",
    "    clip_threshold = 0.97\n",
    "\n",
    "    # Default hyperparameters\n",
    "    cat_params = {\n",
    "        'iterations': 1000,\n",
    "        'learning_rate': 0.03,\n",
    "        'depth': 6,\n",
    "        'eval_metric': 'RMSE',\n",
    "        'random_seed': random_state,\n",
    "        'early_stopping_rounds': 250,\n",
    "        'verbose': 100\n",
    "    }\n",
    "    lgb_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': -1,\n",
    "        'random_state': random_state,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    xgb_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.3,\n",
    "        'max_depth': 6,\n",
    "        'random_state': random_state,\n",
    "        'objective': 'reg:squarederror'\n",
    "    }\n",
    "    lasso_params = {'alpha': 0.001, 'random_state': random_state}\n",
    "    svr_params = {'C': 1.0, 'epsilon': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with too many missing values\n",
    "train = train.loc[:, train.isnull().mean() < Config.missing_threshold]\n",
    "test = test.loc[:, test.isnull().mean() < Config.missing_threshold]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GroupKFold\n",
    "def create_folds(data):\n",
    "    data['folds'] = -1\n",
    "    gkf = GroupKFold(n_splits=Config.n_splits)\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(X=data, groups=data['city']), start=1):\n",
    "        data.loc[val_idx, 'folds'] = fold\n",
    "    return data\n",
    "\n",
    "train = create_folds(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PM2.5 standard deviation per location\n",
    "location_variance = train.groupby('city')[Config.target_col].std().reset_index()\n",
    "location_variance.columns = ['city', 'pm2_5_std']\n",
    "location_variance = location_variance.sort_values(by='pm2_5_std', ascending=False).reset_index(drop=True)\n",
    "location_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers in the target variable\n",
    "plt.figure(figsize = (22, 10))\n",
    "sns.boxplot(train.pm2_5)\n",
    "plt.title('Boxplot showing outliers - target variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations between numerical features and target\n",
    "train_num_df = train.select_dtypes(include=['number'])\n",
    "top10_corrs = abs(train_num_df.corr()['pm2_5']).sort_values(ascending=False).head(10)\n",
    "corr = train_num_df[list(top10_corrs.index)].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8), dpi=150)\n",
    "sns.heatmap(\n",
    "    corr, cmap='RdYlGn', annot=True, center=0, fmt=\".2f\", \n",
    "    annot_kws={\"size\": 9}\n",
    ")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Correlations between the target and other numeric variables', pad=15, fontdict={'size': 14})\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "def feature_engineering(train, test):\n",
    "    le = LabelEncoder()\n",
    "    data = pd.concat([train, test])\n",
    "    data['location'] = data['site_latitude'].astype('str') + '_' + data['site_longitude'].astype('str')\n",
    "    data = data.sort_values(by = ['city','location', 'date', 'hour'])\n",
    "    categorical_cols = data.select_dtypes(include='object').columns.tolist()\n",
    "    categorical_cols = [col for col in categorical_cols if col not in ['date', 'id', 'city', 'country']]\n",
    "    print(f'Categorical columns: {categorical_cols}')\n",
    "\n",
    "    # Date features\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['week'] = data['date'].dt.isocalendar().week\n",
    "    data['day'] = data['date'].dt.day\n",
    "    data['dayofweek'] = data['date'].dt.dayofweek\n",
    "    data['is_weekend'] = data['dayofweek'].isin([5,6]).astype(int)\n",
    "\n",
    "    numerical_cols = data.select_dtypes(exclude='object').columns.tolist()\n",
    "    numerical_cols.remove(Config.target_col)\n",
    "    numerical_cols.remove('folds')\n",
    "    numerical_cols.remove('hour')\n",
    "    numerical_cols.remove('site_latitude')\n",
    "    numerical_cols.remove('site_longitude') \n",
    "    print(f'Numerical columns: {numerical_cols}')\n",
    "\n",
    "    # Fill in missing values by forward and backward fill within each city and location\n",
    "    nan_cols = [col for col in numerical_cols if data[col].isnull().sum() > 0 and col not in [Config.target_col, \"folds\"]]\n",
    "    for col in nan_cols:\n",
    "        for col in nan_cols:\n",
    "            data[col] = (\n",
    "                data.groupby([\"city\", \"location\"])[col]\n",
    "                    .transform(lambda x: x.ffill().bfill())\n",
    "                    .fillna(data[col].median())  # global fallback\n",
    "                )\n",
    "\n",
    "    # Encode categorical features\n",
    "    for col in categorical_cols + ['date']:\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "\n",
    "    # Split back into train and test\n",
    "    train  = data[data['id'].isin(train['id'].unique())]\n",
    "    test = data[data['id'].isin(test['id'].unique())]\n",
    "\n",
    "    features = [col for col in data.columns if col not in \n",
    "                [Config.target_col, Config.id_col, 'folds', 'country', 'city', 'site_id', 'site_latitude', 'site_longitude']]\n",
    "  \n",
    "    return train, test, features\n",
    "\n",
    "train, test, features = feature_engineering(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CatBoost Regressor\n",
    "model = CatBoostRegressor(**Config.cat_params)\n",
    "\n",
    "train_set  = train[train['folds'].isin([1.0, 3.0, 4.0])]\n",
    "val_set = train[train['folds'].isin([2.0])]\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(train_set[features], train_set[Config.target_col], eval_set=(val_set[features], val_set[Config.target_col]), verbose=100,  early_stopping_rounds=250)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importances = model.get_feature_importance(prettified=True)\n",
    "\n",
    "# Display the top features\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top K features based on feature importance\n",
    "top_features = feature_importances.head(Config.top_features)['Feature Id'].tolist()\n",
    "print(f'Top {Config.top_features} features: {top_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly correlated features\n",
    "def drop_highly_correlated_features(data, features, threshold=0.9):\n",
    "    corr_matrix = data[features].corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]\n",
    "    print(f'Dropping {len(to_drop)} highly correlated features: {to_drop}')\n",
    "    reduced_features = [feature for feature in features if feature not in to_drop]\n",
    "    return reduced_features\n",
    "reduced_features = drop_highly_correlated_features(train, top_features, threshold=0.9)\n",
    "\n",
    "print(f'Reduced features: {reduced_features}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation with GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation with GroupKFold\n",
    "oof_predictions = np.zeros(len(train))\n",
    "test_predictions = np.zeros(len(test))\n",
    "fold_rmse_list = []\n",
    "\n",
    "for fold in range(1, Config.n_splits + 1):  \n",
    "    print(f'Training fold {fold}...')\n",
    "   \n",
    "    train_set = train[train['folds'] != fold]\n",
    "    val_set = train[train['folds'] == fold]\n",
    "\n",
    "    # Clip the target of the training set to remove outliers\n",
    "    train_set[Config.target_col] = np.where(train_set[Config.target_col] >= train_set[Config.target_col].quantile(Config.clip_threshold), train_set[Config.target_col].quantile(Config.clip_threshold), train_set[Config.target_col])\n",
    "\n",
    "    model = CatBoostRegressor(**Config.cat_params)\n",
    "    model.fit(train_set[reduced_features], train_set[Config.target_col], eval_set=(val_set[reduced_features], val_set[Config.target_col]))\n",
    "\n",
    "    oof_predictions[val_set.index] = model.predict(val_set[reduced_features])\n",
    "    test_predictions += model.predict(test[reduced_features]) / Config.n_splits\n",
    "\n",
    "    fold_rmse = root_mean_squared_error(val_set[Config.target_col], oof_predictions[val_set.index])\n",
    "    print(f'Fold {fold} RMSE: {fold_rmse}')\n",
    "    fold_rmse_list.append(fold_rmse)\n",
    "\n",
    "    print('-' * 112)\n",
    "\n",
    "# Mean RMSE across all folds\n",
    "mean_rmse = np.mean(fold_rmse_list)\n",
    "print(f'Mean RMSE across all folds: {mean_rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable to store best test predictions\n",
    "best_test_pred = None\n",
    "best_rmse = float(\"inf\")  # track best score\n",
    "best_models = None\n",
    "\n",
    "def objective(trial):\n",
    "    global best_test_pred, best_rmse, best_models\n",
    "\n",
    "    # Suggest hyperparameters for each model\n",
    "    cat_params = {\n",
    "        'iterations': 1000,\n",
    "        'learning_rate': trial.suggest_float('cat_learning_rate', 0.01, 0.1, log=True),\n",
    "        'depth': trial.suggest_int('cat_depth', 4, 10),\n",
    "        'early_stopping_rounds': 250,\n",
    "        'random_seed': Config.random_state,\n",
    "        'verbose': 0\n",
    "    }\n",
    "    lgb_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': trial.suggest_float('lgb_learning_rate', 0.01, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('lgb_max_depth', 3, 12),\n",
    "        'random_state': Config.random_state,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    xgb_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': trial.suggest_float('xgb_learning_rate', 0.01, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('xgb_max_depth', 3, 12),\n",
    "        'random_state': Config.random_state,\n",
    "        'objective': 'reg:squarederror'\n",
    "    }\n",
    "    lasso_params = {'alpha': trial.suggest_float('lasso_alpha', 1e-4, 1.0, log=True), 'random_state': Config.random_state}\n",
    "    svr_params = {\n",
    "        'C': trial.suggest_float('svr_C', 0.1, 10.0, log=True),\n",
    "        'epsilon': trial.suggest_float('svr_epsilon', 0.01, 1.0, log=True)\n",
    "    }\n",
    "\n",
    "    # Cross-validation\n",
    "    oof_predictions = np.zeros(len(train))\n",
    "    fold_rmse_list = []\n",
    "    fold_test_preds = []\n",
    "\n",
    "    for fold in range(1, Config.n_splits + 1):\n",
    "        train_set = train[train['folds'] != fold].copy()\n",
    "        val_set = train[train['folds'] == fold].copy()\n",
    "\n",
    "        # Clip target\n",
    "        clip_val = train_set[Config.target_col].quantile(Config.clip_threshold)\n",
    "        train_set[Config.target_col] = np.where(\n",
    "            train_set[Config.target_col] >= clip_val, clip_val, train_set[Config.target_col]\n",
    "        )\n",
    "\n",
    "        # Define models \n",
    "        models = {\n",
    "            \"cat\": CatBoostRegressor(**cat_params),\n",
    "            \"lgb\": LGBMRegressor(**lgb_params),\n",
    "            \"xgb\": XGBRegressor(**xgb_params),\n",
    "            \"lasso\": Lasso(**lasso_params),\n",
    "            \"svr\": SVR(**svr_params)\n",
    "        }\n",
    "\n",
    "        val_preds = np.zeros((len(val_set), len(models)))\n",
    "        test_preds = np.zeros((len(test), len(models)))\n",
    "\n",
    "        # Train each model and predict\n",
    "        for i, (name, model) in enumerate(models.items()):\n",
    "            model.fit(train_set[reduced_features], train_set[Config.target_col])\n",
    "            val_preds[:, i] = model.predict(val_set[reduced_features])\n",
    "            test_preds[:, i] = model.predict(test[reduced_features])\n",
    "\n",
    "        # Ensemble with equal weights\n",
    "        oof_predictions[val_set.index] = np.mean(val_preds, axis=1)\n",
    "        fold_test_preds.append(np.mean(test_preds, axis=1))\n",
    "\n",
    "        # Fold RMSE\n",
    "        fold_rmse = root_mean_squared_error(val_set[Config.target_col], oof_predictions[val_set.index])\n",
    "        fold_rmse_list.append(fold_rmse)\n",
    "    \n",
    "    mean_rmse = np.mean(fold_rmse_list)\n",
    "    mean_test_pred = np.mean(fold_test_preds, axis=0)\n",
    "\n",
    "    # Save best test prediction\n",
    "    if mean_rmse < best_rmse:\n",
    "        best_rmse = mean_rmse\n",
    "        best_test_pred = mean_test_pred\n",
    "        best_models = {name: model for name, model in models.items()}\n",
    "\n",
    "    return mean_rmse\n",
    "\n",
    "# Run Optuna study to optimize hyperparameters\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=30)  # adjust n_trials\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "print(\"Best RMSE:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best models\n",
    "folder_name = f\"./weights/{best_rmse:.2f}\"  # keep 4 decimal places\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "for name, model in best_models.items():\n",
    "    joblib.dump(model, f\"{folder_name}/best_model_{name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance from best CatBoost model\n",
    "plt.figure(figsize=(20, 16))\n",
    "feature_importances_df = pd.DataFrame(best_models['cat'].feature_importances_, columns=['Importances'])\n",
    "feature_importances_df['Feature'] = reduced_features\n",
    "sns.barplot(x='Importances', y='Feature', data=feature_importances_df.sort_values(by=['Importances'], ascending=False).head(20))\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_submission(test, best_test_pred):\n",
    "    test['pm2_5'] = best_test_pred\n",
    "    submission = test[[Config.id_col, 'pm2_5']]\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    submission.head()\n",
    "\n",
    "prepare_submission(test, best_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best models and save submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best models\n",
    "rmse = 27.84 # replace with your choice\n",
    "folder_name = f\"./weights/{rmse:.2f}\"\n",
    "models = {}\n",
    "for model_name in ['cat', 'lgb', 'xgb', 'lasso', 'svr']:\n",
    "    models[model_name] = joblib.load(f\"{folder_name}/best_model_{model_name}.pkl\")  \n",
    "\n",
    "# Prepare test predictions\n",
    "test_preds = np.zeros((len(test), len(models)))\n",
    "\n",
    "# Predict\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    test_preds[:, i] = model.predict(test[reduced_features])\n",
    "\n",
    "# Ensemble with equal weights\n",
    "final_test_pred = np.mean(test_preds, axis=1)\n",
    "\n",
    "# Save final submission\n",
    "# prepare_submission(test, final_test_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI7101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
