{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_rows = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set maximum number of rows to display\n",
    "pd.set_option('display.max_rows', 10000)  # Show up to 100 rows\n",
    "pd.set_option('display.max_columns', 2000)  # Show up to 20 columns\n",
    "pd.set_option('display.width', 1000)  # Set display width\n",
    "pd.set_option('display.max_colwidth', 50)  # Max characters per column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    target_col = 'pm2_5'\n",
    "    n_splits = 4\n",
    "    random_state = 42\n",
    "    id_col = 'id'\n",
    "    missing_threshold = 0.7\n",
    "    top_features = 70\n",
    "    clip_threshold = 0.97\n",
    "    corr_threshold = 0.9\n",
    "\n",
    "    # Default hyperparameters\n",
    "    cat_params = {\n",
    "        'iterations': 1000,\n",
    "        'learning_rate': 0.03,\n",
    "        'depth': 6,\n",
    "        'eval_metric': 'RMSE',\n",
    "        'random_seed': random_state,\n",
    "        'early_stopping_rounds': 250,\n",
    "        'verbose': 100\n",
    "    }\n",
    "    lgb_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': -1,\n",
    "        'random_state': random_state,\n",
    "        'verbosity': -1\n",
    "    }\n",
    "    xgb_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.3,\n",
    "        'max_depth': 6,\n",
    "        'random_state': random_state,\n",
    "        'objective': 'reg:squarederror'\n",
    "    }\n",
    "    lasso_params = {'alpha': 0.001, 'random_state': random_state}\n",
    "    svr_params = {'C': 1.0, 'epsilon': 0.1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('dataset/Train.csv')\n",
    "test = pd.read_csv('dataset/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_train_test_columns(train_df, test_df, target_col=None):\n",
    "    \"\"\"\n",
    "    Ensure train and test datasets have the same columns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_df : pandas.DataFrame\n",
    "        Training dataset\n",
    "    test_df : pandas.DataFrame\n",
    "        Test dataset\n",
    "    target_col : str, optional\n",
    "        Target column name to exclude from alignment (if present in train but not test)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (train_df_aligned, test_df_aligned)\n",
    "        Aligned train and test dataframes with the same columns\n",
    "    \"\"\"\n",
    "    print(f\"Train columns before alignment: {len(train_df.columns)}\")\n",
    "    print(f\"Test columns before alignment: {len(test_df.columns)}\")\n",
    "    \n",
    "    # Get common columns (excluding target if specified)\n",
    "    if target_col not in train_df.columns:\n",
    "        raise ValueError(f\"Target column {target_col} not found in train dataset\")\n",
    "\n",
    "    common_cols = [col for col in train_df.columns if col in test_df.columns]\n",
    "    print(f\"Number of Common columns: {len(common_cols)}\")\n",
    "    \n",
    "    # Find columns that are in train but not in test\n",
    "    train_only_cols = [col for col in train_df.columns if col not in test_df.columns]\n",
    "    if train_only_cols:\n",
    "        print(f\"Columns in train but not in test: {train_only_cols}\")\n",
    "    \n",
    "    # Find columns that are in test but not in train\n",
    "    test_only_cols = [col for col in test_df.columns if col not in train_df.columns]\n",
    "    if test_only_cols:\n",
    "        print(f\"Columns in test but not in train: {test_only_cols}\")\n",
    "    \n",
    "    # Align both datasets to have the same columns\n",
    "    train_aligned = train_df[common_cols + [target_col]].copy()\n",
    "    test_aligned = test_df[common_cols].copy()\n",
    "\n",
    "\n",
    "    print(f\"Train columns after alignment: {len(train_aligned.columns)}\")\n",
    "    print(f\"Test columns after alignment: {len(test_aligned.columns)}\")\n",
    "    \n",
    "    return train_aligned, test_aligned\n",
    "\n",
    "# Apply the function to align train and test columns\n",
    "train, test = align_train_test_columns(train, test, target_col=Config.target_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CORRECTED VERSION: Remove columns with too many missing values\n",
    "# print the number of columns before removing\n",
    "print(f\"Number of columns before removing: {len(train.columns)}\")\n",
    "\n",
    "before_removing_columns = train.columns\n",
    "# Calculate null percentages BEFORE removing columns\n",
    "null_percentages = train.isnull().mean()\n",
    "train = train.loc[:, null_percentages < Config.missing_threshold]\n",
    "after_removing_columns = train.columns\n",
    "removed_columns = set(before_removing_columns) - set(after_removing_columns)\n",
    "\n",
    "# null percentage of removed columns (using the original null percentages)\n",
    "if removed_columns:\n",
    "    removed_null_percentages = null_percentages[list(removed_columns)]\n",
    "    print(f\"Null percentage of removed columns:\")\n",
    "    print(removed_null_percentages)\n",
    "    print(f\"Number of removed columns: {len(removed_columns)}\")\n",
    "    print(f\"Columns removed: {list(removed_columns)}\")\n",
    "else:\n",
    "    print(\"No columns were removed\")\n",
    "\n",
    "# Remove the same columns from test set (based on removed_columns from train)\n",
    "if removed_columns:\n",
    "    # Get columns to keep in test (all columns except the ones removed from train)\n",
    "    test_columns_to_keep = [col for col in test.columns if col not in removed_columns]\n",
    "    test = test[test_columns_to_keep]\n",
    "    print(f\"Test columns after removing same columns as train: {len(test.columns)}\")\n",
    "else:\n",
    "    print(\"No columns removed from test (no columns were removed from train)\")\n",
    "\n",
    "print(f\"Final train columns: {len(train.columns)}\")\n",
    "print(f\"Final test columns: {len(test.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GroupKFold\n",
    "def create_folds(data):\n",
    "    data['folds'] = -1\n",
    "    gkf = GroupKFold(n_splits=Config.n_splits)\n",
    "    for fold, (train_idx, val_idx) in enumerate(gkf.split(X=data, groups=data['city']), start=1):\n",
    "        data.loc[val_idx, 'folds'] = fold\n",
    "    return data\n",
    "\n",
    "train = create_folds(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PM2.5 standard deviation per location\n",
    "location_variance = train.groupby('city')[Config.target_col].std().reset_index()\n",
    "location_variance.columns = ['city', 'pm2_5_std']\n",
    "location_variance = location_variance.sort_values(by='pm2_5_std', ascending=False).reset_index(drop=True)\n",
    "print(location_variance)\n",
    "\n",
    "print()\n",
    "# Calculate PM2.5 mean per location\n",
    "location_mean = train.groupby('city')[Config.target_col].mean().reset_index()\n",
    "location_mean.columns = ['city', 'pm2_5_mean']\n",
    "location_mean = location_mean.sort_values(by='pm2_5_mean', ascending=False).reset_index(drop=True)\n",
    "print(location_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.histplot(train[\"pm2_5\"], bins=50, kde=True, ax=axes[0])\n",
    "axes[0].set_title(\"Raw Distribution\")\n",
    "\n",
    "sns.histplot(train[\"pm2_5\"], bins=50, kde=True, ax=axes[1])\n",
    "axes[1].set_xlim(0, 100)\n",
    "axes[1].set_title(\"Zoomed in (0-100)\")\n",
    "\n",
    "sns.histplot(np.log1p(train[\"pm2_5\"]), bins=50, kde=True, ax=axes[2])\n",
    "axes[2].set_title(\"Log-transformed\")\n",
    "axes[2].set_xlabel(\"log(pm2_5+1)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_df = train.select_dtypes(include=['number'])\n",
    "\n",
    "# Correlation with target\n",
    "corr_with_target = train_num_df.corr()['pm2_5'].drop('pm2_5').sort_values(key=abs, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 15), dpi=120)\n",
    "sns.barplot(x=abs(corr_with_target.values), y=corr_with_target.index, palette=\"RdYlGn\")\n",
    "plt.title(\"Correlation of Numerical Features with Target (pm2_5)\")\n",
    "plt.xlabel(\"Correlation coefficient\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target outliers\n",
    "plt.figure(figsize=(10, 6), dpi=300)\n",
    "sns.boxplot(x=train[\"pm2_5\"])\n",
    "plt.title(\"Boxplot of PM2.5\")\n",
    "plt.xlabel(\"PM2.5\")\n",
    "plt.show()\n",
    "\n",
    "# Comment on the outliers\n",
    "# There are several outliers in the PM2.5 distribution, with some values significantly higher than the majority of the data points. These outliers may represent extreme pollution events or measurement errors. It is important to consider how to handle these outliers in the modeling process, as they can impact model performance and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations between numerical features and target\n",
    "train_num_df = train.select_dtypes(include=['number'])\n",
    "top10_corrs = abs(train_num_df.corr()['pm2_5']).sort_values(ascending=False).head(10)\n",
    "corr = train_num_df[list(top10_corrs.index)].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8), dpi=150)\n",
    "sns.heatmap(\n",
    "    corr, cmap='RdYlGn', annot=True, center=0, fmt=\".2f\", \n",
    "    annot_kws={\"size\": 9}\n",
    ")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Correlations between the target and other numeric variables', pad=15, fontdict={'size': 14})\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations between features that contain 'angle' \n",
    "angle_features = [col for col in train.columns if 'solar_zenith_angle' in col]\n",
    "angle_corr = train[angle_features].corr()\n",
    "plt.figure(figsize=(12, 10), dpi=300)\n",
    "sns.heatmap(\n",
    "    angle_corr, cmap='RdYlGn', annot=True, center=0, fmt=\".6f\", \n",
    "    annot_kws={\"size\": 7}, vmin=-1, vmax=1\n",
    ")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Correlations between features that contain \"solar zenith angle\"', pad=15, fontdict={'size': 14})\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "\n",
    "def feature_engineering(train, test):\n",
    "    le = LabelEncoder()\n",
    "    data = pd.concat([train, test])\n",
    "    data['location'] = data['site_latitude'].astype('str') + '_' + data['site_longitude'].astype('str')\n",
    "    data = data.sort_values(by = ['city','location', 'date', 'hour'])\n",
    "    categorical_cols = data.select_dtypes(include='object').columns.tolist()\n",
    "    categorical_cols = [col for col in categorical_cols if col not in ['date', 'id', 'city', 'country']]\n",
    "    print(f'Categorical columns: {categorical_cols}')\n",
    "\n",
    "    # Date features\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['month'] = data['date'].dt.month\n",
    "    data['week'] = data['date'].dt.isocalendar().week\n",
    "    data['day'] = data['date'].dt.day\n",
    "    data['dayofweek'] = data['date'].dt.dayofweek\n",
    "    data['is_weekend'] = data['dayofweek'].isin([5,6]).astype(int)\n",
    "\n",
    "    numerical_cols = data.select_dtypes(exclude='object').columns.tolist()\n",
    "    numerical_cols.remove(Config.target_col)\n",
    "    numerical_cols.remove('folds')\n",
    "    numerical_cols.remove('hour')\n",
    "    numerical_cols.remove('site_latitude')\n",
    "    numerical_cols.remove('site_longitude') \n",
    "    print(f'Numerical columns: {numerical_cols}')\n",
    "\n",
    "    # Fill in missing values by forward and backward fill within each city and location\n",
    "    nan_cols = [col for col in numerical_cols if data[col].isnull().sum() > 0 and col not in [Config.target_col, \"folds\"]]\n",
    "    for col in nan_cols:\n",
    "        data[col] = (\n",
    "            data.groupby([\"city\", \"location\"])[col]\n",
    "                .transform(lambda x: x.ffill().bfill())\n",
    "                .fillna(data[col].median())  # global fallback\n",
    "            )\n",
    "\n",
    "    # Encode categorical features\n",
    "    for col in categorical_cols + ['date']:\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "\n",
    "    # Split back into train and test\n",
    "    train  = data[data['id'].isin(train['id'].unique())]\n",
    "    test = data[data['id'].isin(test['id'].unique())]\n",
    "\n",
    "    features = [col for col in data.columns if col not in \n",
    "                [Config.target_col, Config.id_col, 'folds', 'country', 'city', 'site_id', 'site_latitude', 'site_longitude']]\n",
    "  \n",
    "    return train, test, features\n",
    "\n",
    "train, test, features = feature_engineering(train, test)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_feature_selection(X, y, k=Config.top_features):\n",
    "    \"\"\"\n",
    "    Select top-k features based on CatBoost feature importance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        Feature matrix\n",
    "    y : pd.Series or np.ndarray\n",
    "        Target vector\n",
    "    k : int\n",
    "        Number of top features to select\n",
    "    \"\"\"\n",
    "    model = CatBoostRegressor(**Config.cat_params)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    feature_importances = model.get_feature_importance(prettified=True)\n",
    "    top_features = feature_importances.head(k)['Feature Id'].tolist()\n",
    "\n",
    "    return top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly correlated features\n",
    "def drop_highly_correlated_features(X, threshold=0.9):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > threshold)]\n",
    "    print(f'Dropping {len(to_drop)} highly correlated features: {to_drop}')\n",
    "    reduced_features = [feature for feature in X.columns.tolist() if feature not in to_drop]\n",
    "    return reduced_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel:\n",
    "    def __init__(self, top_features=30, corr_threshold=0.9, clip_threshold=0.99):\n",
    "        self.top_features = top_features\n",
    "        self.corr_threshold = corr_threshold\n",
    "        self.clip_threshold = clip_threshold\n",
    "        self.models = None\n",
    "        self.reduced_features = None\n",
    "        self.best_params = None\n",
    "\n",
    "    def _clip_target(self, y):\n",
    "        clip_val = np.quantile(y, self.clip_threshold)\n",
    "        return np.where(y >= clip_val, clip_val, y)\n",
    "\n",
    "    def _feature_selection(self, X, y):\n",
    "        top_feats = top_k_feature_selection(X, y, k=self.top_features)\n",
    "        self.reduced_features = drop_highly_correlated_features(X[top_feats], threshold=self.corr_threshold)\n",
    "\n",
    "    def _fit_models(self, X, y, models):\n",
    "        for name, model in models.items():\n",
    "            model.fit(X[self.reduced_features], y)\n",
    "        return models\n",
    "\n",
    "    def cross_val_fit(self, X, y, folds, models, X_test=None):\n",
    "        \"\"\"Run CV to evaluate hyperparameters; returns OOF, test predictions, mean RMSE.\"\"\"\n",
    "        oof_preds = np.zeros(len(y))\n",
    "        fold_test_preds = [] if X_test is not None else None\n",
    "        fold_rmse_list = []\n",
    "\n",
    "        unique_folds = np.unique(folds)\n",
    "\n",
    "        for fold in unique_folds:\n",
    "            train_idx = folds != fold\n",
    "            val_idx = folds == fold\n",
    "            X_train, y_train = X[train_idx], y[train_idx]\n",
    "            X_val, y_val = X[val_idx], y[val_idx]\n",
    "\n",
    "            y_train_clipped = self._clip_target(y_train)\n",
    "\n",
    "            val_preds = np.zeros((len(X_val), len(models)))\n",
    "            test_preds = np.zeros((len(X_test), len(models))) if X_test is not None else None\n",
    "\n",
    "            # Train each model\n",
    "            models_fold = self._fit_models(X_train, y_train_clipped, models)\n",
    "            for i, (name, model) in enumerate(models_fold.items()):\n",
    "                val_preds[:, i] = model.predict(X_val[self.reduced_features])\n",
    "                if X_test is not None:\n",
    "                    test_preds[:, i] = model.predict(X_test[self.reduced_features])\n",
    "\n",
    "            # Ensemble\n",
    "            oof_preds[val_idx] = val_preds.mean(axis=1)\n",
    "            if X_test is not None:\n",
    "                fold_test_preds.append(test_preds.mean(axis=1))\n",
    "\n",
    "            # Fold RMSE\n",
    "            fold_rmse = np.sqrt(np.mean((y_val - oof_preds[val_idx])**2))\n",
    "            fold_rmse_list.append(fold_rmse)\n",
    "\n",
    "        mean_rmse = np.mean(fold_rmse_list)\n",
    "        final_test_preds = np.mean(fold_test_preds, axis=0) if X_test is not None else None\n",
    "        return oof_preds, final_test_preds, mean_rmse\n",
    "\n",
    "    def fit_final(self, X, y, models):\n",
    "        \"\"\"Train final ensemble on full training data after hyperparameter selection.\"\"\"\n",
    "        y_clipped = self._clip_target(y)\n",
    "        self._feature_selection(X, y_clipped)\n",
    "        self.models = self._fit_models(X, y_clipped, models)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using the ensemble (mean of all models).\"\"\"\n",
    "        test_preds = np.zeros((len(X), len(self.models)))\n",
    "        for i, (name, model) in enumerate(self.models.items()):\n",
    "            test_preds[:, i] = model.predict(X[self.reduced_features])\n",
    "        return np.mean(test_preds, axis=1)\n",
    "\n",
    "ensemble = EnsembleModel(top_features=Config.top_features,\n",
    "                         corr_threshold=Config.corr_threshold,\n",
    "                         clip_threshold=Config.clip_threshold)\n",
    "ensemble._feature_selection(train[features], train[Config.target_col].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation with GroupKFold for hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    models = {\n",
    "        \"cat\": CatBoostRegressor(\n",
    "            iterations=1000,\n",
    "            learning_rate=trial.suggest_float('cat_lr', 0.01, 0.1, log=True),\n",
    "            depth=trial.suggest_int('cat_depth', 4, 10),\n",
    "            random_seed=Config.random_state,\n",
    "            verbose=0,\n",
    "            early_stopping_rounds=250\n",
    "        ),\n",
    "        \"lgb\": LGBMRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=trial.suggest_float('lgb_lr', 0.01, 0.1, log=True),\n",
    "            max_depth=trial.suggest_int('lgb_depth', 3, 12),\n",
    "            random_state=Config.random_state,\n",
    "            verbosity=-1\n",
    "        ),\n",
    "        \"xgb\": XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=trial.suggest_float('xgb_lr', 0.01, 0.1, log=True),\n",
    "            max_depth=trial.suggest_int('xgb_depth', 3, 12),\n",
    "            random_state=Config.random_state,\n",
    "            objective='reg:squarederror'\n",
    "        ),\n",
    "        \"lasso\": Lasso(alpha=trial.suggest_float('lasso_alpha', 1e-4, 1.0, log=True),\n",
    "                       random_state=Config.random_state),\n",
    "        \"svr\": SVR(\n",
    "            C=trial.suggest_float('svr_C', 0.1, 10.0, log=True),\n",
    "            epsilon=trial.suggest_float('svr_eps', 0.01, 1.0, log=True)\n",
    "        )\n",
    "    }\n",
    "\n",
    "    _, _, mean_rmse = ensemble.cross_val_fit(\n",
    "        train[features],\n",
    "        train[Config.target_col].values,\n",
    "        folds=train['folds'].values,\n",
    "        models=models\n",
    "    )\n",
    "        \n",
    "    return mean_rmse\n",
    "\n",
    "# Optimize hyperparameters\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final train on full data and predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best hyperparameters\n",
    "best_params = study.best_params\n",
    "Config.cat_params['learning_rate'] = best_params['cat_lr']\n",
    "Config.cat_params['depth'] = best_params['cat_depth']\n",
    "Config.lgb_params['learning_rate'] = best_params['lgb_lr']\n",
    "Config.lgb_params['max_depth'] = best_params['lgb_depth']\n",
    "Config.xgb_params['learning_rate'] = best_params['xgb_lr']   \n",
    "Config.xgb_params['max_depth'] = best_params['xgb_depth']\n",
    "Config.lasso_params['alpha'] = best_params['lasso_alpha']\n",
    "Config.svr_params['C'] = best_params['svr_C']\n",
    "Config.svr_params['epsilon'] = best_params['svr_eps']\n",
    "\n",
    "# Define final models with best hyperparameters\n",
    "best_models = {\n",
    "    \"cat\": CatBoostRegressor(**Config.cat_params),\n",
    "    \"lgb\": LGBMRegressor(**Config.lgb_params),\n",
    "    \"xgb\": XGBRegressor(**Config.xgb_params),\n",
    "    \"lasso\": Lasso(**Config.lasso_params),\n",
    "    \"svr\": SVR(**Config.svr_params)\n",
    "}\n",
    "\n",
    "ensemble.fit_final(train[features], train[Config.target_col].values, best_models)\n",
    "final_test_preds = ensemble.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best models\n",
    "folder_name = f\"./weights/{study.best_value:.2f}\"  # keep 4 decimal places\n",
    "print(\"Saving models to:\", folder_name)\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "for name, model in best_models.items():\n",
    "    joblib.dump(model, f\"{folder_name}/best_model_{name}.pkl\")\n",
    "\n",
    "# Save reduced feature list\n",
    "with open(f\"{folder_name}/reduced_features.json\", \"w\") as f:\n",
    "    json.dump(ensemble.reduced_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance from final CatBoost model\n",
    "plt.figure(figsize=(20, 16))\n",
    "feature_importances_df = pd.DataFrame(best_models['cat'].feature_importances_, columns=['Importances'])\n",
    "feature_importances_df['Feature'] = ensemble.reduced_features\n",
    "sns.barplot(x='Importances', y='Feature', data=feature_importances_df.sort_values(by=['Importances'], ascending=False).head(20))\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_submission(test, best_test_pred, save_path='output/submission.csv'):\n",
    "    \"\"\"Prepare submission file.\"\"\"\n",
    "    test[Config.target_col] = best_test_pred\n",
    "    submission = test[[Config.id_col, Config.target_col]]\n",
    "    submission.to_csv(save_path, index=False)\n",
    "    submission.head()\n",
    "    \n",
    "prepare_submission(test, final_test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI7101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
